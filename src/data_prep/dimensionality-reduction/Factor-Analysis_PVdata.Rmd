# Factor Analysis

## Notes and references

-   Exploratory Factor Analysis (EFA) tutorial: <https://rpubs.com/pjmurphy/758265>

-   notes from the textbook "Applied Multivariate Statistical Analysis" in the same directory of this folder

-   reference paper of past year project on Well-Being

-   source: <https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/factor-analysis/A-simple-example-of-FA/index.htmlZ>

-   according to this article (<https://journals.sagepub.com/doi/full/10.1177/0095798418771807>) it is better to perform EFA only on variables we suspect to be generated by a latent factor. Thus, it is better to follow the same procedure we used for PCA

## Settings

```{r}
#loaded librarires
library(dplyr)
library(psych) #for KMO test and principal()
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check
library(GGally) #for ggcorr
library(ggplot2)
library(elasticnet) #trying out sparse principal component analysis [spca()]
```

```{r, setup}
#DIRECTORIES
root_proj_dir = "../../"
dataset_dir = paste(root_proj_dir,"/data/pisa_wPV_grouped_bysch.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#IMPORTING THE DATASET
pisa_data <- read.csv(file=dataset_dir)
```

```{r}
#some adjustments on the data
pisa_data$X <- NULL
pisa_data$schID <- NULL
pisa_data$CNT <- as.factor(pisa_data$CNT)
pisa_data$CNTSCHID <- as.factor(pisa_data$CNTSCHID)
pisa_data$CNTSTUID <- as.factor(pisa_data$CNTSTUID)
```

# Data preprocessing: standardization

Saving plausible values in a separate dataframe. Later we'll add them to the scores dataset

```{r}
#paluesible values dataset
plausible_values <- pisa_data %>% select(starts_with("PV"))
#excluding PV frmo the dataset to compute the factor analysis
pisa_data <- pisa_data %>% select(-starts_with("PV")) #excluding target variables
```

```{r}
#standardize the variables
transformed_data <- as.data.frame(scale(select_if(pisa_data,is.numeric)))
transformed_data$CNT <- pisa_data$CNT #adding CNT column

pisa_data <- transformed_data
rm(transformed_data)
```

Quick look at the data

```{r}
boxplot(select_if(pisa_data,is.numeric),las=2)
```

# Grouping the variables

Grouping variables suspected to be generated by a latent factor (The same variable may appear in more than one group, according to our choices):

```{r}
grouped_variables <-list()
#list of grouped variables

##Technology
#c("ICTCLASS","ICTHOME","ICTOUTSIDE","ICTRES","AUTICT","COMPICT","INTICT","ENTUSE","HOMESCH","USESCH", "ICTSCH","RATCMP1")

grouped_variables[["ICT at home"]] <- c("ICTHOME","ICTRES","ENTUSE","HOMESCH")
grouped_variables[["Relationship with ICT"]] <- c("AUTICT","COMPICT","INTICT","ENTUSE", "HOMESCH", "USESCH")
grouped_variables[["ICT at school"]] <- c("ICTCLASS","ICTOUTSIDE","USESCH", "ICTSCH","RATCMP1")

##Psichology
grouped_variables[["Well-being"]] <- c("EUDMO","SWBP","EMOSUPS")
grouped_variables[["Attitude towards the others"]] <- c("COMPETE","RESILIENCE", "GFOFAIL")
grouped_variables[["Relationship with school environment"]] <- c("PERCOOP","PERCOMP","PERFEED","BELONG","BEINGBULLIED")


##Culture
grouped_variables[["Cultural possesion"]] <- c("CULTPOSS","HEDRES")
grouped_variables[["Attitude towards school"]] <- c("LMINS","MMINS","STUBEHA","ATTLNACT")
grouped_variables[["Reading"]] <- c("JOYREAD", "SCREADCOMP")

##Familty
grouped_variables[["Family economic status"]] <- c("WEALTH","ESCS","HOMEPOS","BFMJ2","BMMJ1","HISCED","HISEI")

##Teaching
grouped_variables[["Teachers' degree"]] <- c("PROAT5AB","PROAT5AM","PROAT6")
grouped_variables[["Teacher support"]] <- c("TEACHINT","TEACHSUP","STIMREAD","TEACHBEHA")

##School
grouped_variables[["School size"]] <- c("STRATIO","SCHSIZE","CLSIZE")
grouped_variables[["Equipment of the school"]] <- c("EDUSHORT","STAFFSHORT")

#groups
group_list <- names(grouped_variables)
```

Some graphs to validate the choice made while grouping the variables

```{r}
p_ <- GGally::print_if_interactive

for(group_name in group_list){
  
  p_(ggcorr(pisa_data[,grouped_variables[[group_name]]],
         label=TRUE,label_size = 2) +
    ggtitle(group_name))
}
```

# Performing EFA

## Preliminary tests

-   cortest.bartlett(): test to see if the variables in the dataframe are uncorrellated. H0: correlation matrix sigma = Identity matrix (i.e. uncorrelated variables)

-   KMO: another check on uncorrelation

-   multivariate normality to perform factor analysis with the maximum likelihood estimation method

## Selecting the number of factors

the following methods are useful to select the initial number of factors. The final choice should be made based on the portion of variance explained

```{r}
nfactors <- list()

for(group in group_list){
  #scree plot
  #scree(pisa_data[,grouped_variables[[group]]], 
  #      pc=TRUE, 
  #      main = paste("Scree plot:", group))
  
  #parallel analysis
  parallel.an <- fa.parallel(pisa_data[,grouped_variables[[group]]], 
              main = paste("Parallel Analysis Scree Plots:",group))
  
  nfactors[[group]]$FA <- parallel.an$nfact
  nfactors[[group]]$PC <- parallel.an$ncomp
  
  #a method from psych package with many more criteria
  #nfactors(cor(pisa_data[,grouped_variables[[group]]]),
  #         title = paste("Number of factors", group),
  #         plot=FALSE)
}
```

## Fitting the models

Options:

-   factanal(): performs a EFA by maximum likelihood estimation [package stats]

-   princomp(): perform PCA in the stadard way, as seen in lecture [package stats]

-   fa(): performs various types of EFA, we can decided the most suited one [package psych]

-   principal(): performs PCA in a more sophisticated way, see the documentation in this folder [package psych]

```{r}
#TRIED methods:
# FA with ML
fit_FA_ML <- list() #factanal() 

# classical PCA 
fit_PCA_classic <- list() #princomp()

# FA with principal factor method
fit_FA_PF <- list() #fa() 

# advanced PCA
fit_PCA_advanced <- list()

#fitting the models
for(group in group_list){
  #FA with ML
  fit_FA_ML[[group]] <- fa(r = select_if(pisa_data[,grouped_variables[[group]]],is.numeric),
                             factors = nfactors[[group]]$FA,
                             rotation = "promax",
                             fm = "mle")
  
  #classic PCA
  fit_PCA_classic[[group]] <- princomp(pisa_data[,grouped_variables[[group]]])
  #FA with PF
  fit_FA_PF[[group]] <- fa(r = cor(pisa_data[,grouped_variables[[group]]]),
                            nfactors = nfactors[[group]]$FA,
                            rotate = "promax")
  #advanced PCA
  fit_PCA_advanced[[group]] <- principal(r = cor(pisa_data[,grouped_variables[[group]]]),
                               nfactors = nfactors[[group]]$PC, 
                               rotate = "promax", 
                               scores = TRUE)
  
}
```

**A note on rotation:** loading matrix (L) is unique up to rotation made through orthogonal matrices. Thus, we have can provide as an option to this functions a rotation method to ease the interpretability of the loadings. There a two kind of rotations:

-   orthogonal rotation methods: if we assume that the extracted factors are independent

    -   "varimax": optimized to reduce cross loadings and to minimize smaller loading values, making factor models clearer

    -   "quartimax": works to reduce the number of variables needed to explain a factor, making interpretation easier

    -   "equamax": compromise between varimax and quartimax

-   oblique rotation methods: if we assume that the extracted factors are not independent

    -   "promax": Promax rotation is popular for its ability to handle large datasets efficiently. The approach also tends to result in greater correlation values between factors.

    -   The direct "oblimin" rotation approach is somewhat less efficient with large datasets, but can produce a simpler factor structure.

[reference: <https://rpubs.com/pjmurphy/758265> for]

# Loadings and GOF

## FA with Principal Factor solution method

Goodness of the model:

-   communalities: percentage of the variability of a single variable in the original dataframe explained by the common factors

-   factor.fit() compute the following quantity to asses the GOF of the model:

    -\> 1 - sum(residual_mat\*residual_mat')/sum(R\*R')

    where the sum is performed over each el. of the matrix

```{r}
for(group in group_list){
  cat("\nGroup", group, "\n")
  #communalities
  cat("->Communalities\n")
  print(fit_FA_PF[[group]]$communality)
  
  #fit of the model
  cat("->Fit of the model\n")
  print(factor.fit(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
             fit_FA_PF[[group]]))
}
```

Visualizing the loadings:

```{r}
#Factor Analysis with method "pa"
for(group in group_list){
  fa.diagram(fit_FA_PF[[group]])
  for(i in 1:dim(fit_FA_PF[[group]]$loadings)[2]){
    barplot(fit_FA_PF[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

## FA with ML method

Variance explained and GOF of the model (test to evaluate H0: sigma = LL' + phi)

```{r}
#variance explained
for(group in group_list){
  cat("GROUP", group, "\n\n")
  #communalities
  cat("-> Communalities\n")
  print(fit_FA_ML[[group]]$communality)
  
  #fit of the model
  cat("-> Fit coefficient:\n")
  print(factor.fit(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
             fit_FA_ML[[group]]))
  #GOF test
  cat("-> p-value for the GOF test\n")
  print(fit_FA_ML[[group]]$PVAL)
  
  cat("\n")
}
```

Visualize the loadings:

```{r}
#Factor Analysis with ML method 
for(group in group_list){
  fa.diagram(fit_FA_ML[[group]]$loadings)
  
}
```

## PCA

Evaluate the GOF of the model:

```{r}
for(group in group_list){
  cat("Group", group, ":", 
      fit_PCA_advanced[[group]]$fit,"\n")
  #fit of the model for group wrt off-diag elements for group
  cat("-> fit: ", fit_PCA_advanced[[group]]$fit,"\n")
}
```

Visualize the loadings:

```{r}
#Principal Component method
for(group in group_list){
  for(i in 1:nfactors[[group]]$PC){
    barplot(fit_PCA_advanced[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

## Classic PCA

```{r}
for(group in group_list){
  print(summary(fit_PCA_classic[[group]]))
}
```

```{r}
#Principal Component method
for(group in group_list){
  for(i in 1:nfactors[[group]]$PC){
    barplot(fit_PCA_classic[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

# Computing the scores

```{r}
#little utility to compute the scores from a fit of principal() and the dataframe on which the fit is computed
scores <- function(fit,data){
  return(as.data.frame(as.matrix(data)%*%fit$loadings))
}

#utiliy to name the dataframe
add_prefix <- function(prefix,x){
  return(paste(prefix,x,sep="_"))
}

FA_PC_scores <- data.frame(matrix(nrow = dim(pisa_data)[1], ncol = 0))
for(group in group_list){
  #score names
  PC_names <- as.character(1:nfactors[[group]])
  PC_names <- sapply(PC_names, add_prefix, prefix = group)
  PC_names <- sapply(PC_names, add_prefix, prefix = "PC")
  
  #computing the scores
  FA_PC_scores[,PC_names] <- scores(fit_FA_PC[[group]],select_if(pisa_data[,grouped_variables[[group]]],is.numeric))
}
```

Building and writing the score dataset:

```{r}
#add CNT column
FA_PC_scores$CNT <- pisa_data$CNT
#adding PVs
FA_PC_scores[,names(plausible_values)] <- plausible_values
```

```{r eval=FALSE, include=FALSE}
saving_dir <- "../../data"
# write.csv(FA_PC_scores, file=paste(saving_dir,"pisa_wPV_PCscores.csv",sep="/"))
```
