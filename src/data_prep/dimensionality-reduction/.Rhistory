file
getwd()
dataset_dir = "C:/Users/modin/Desktop/Ettore/UNIVERSITA/PISA_PROJECT/progetto-applied/data/"
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_wPV_grouped_bysch_schtype.csv",sep=""))
head(pisa_data)
head(pisa_data)
head(pisa_data)
pisa_data$X<-NULL
head(pisa_data)
pisa_data$CNTSCHID<-NULL
pisa_data$CNTSTUID<-NULL
head(pisa_data)
head(pisa_data)
write.csv("C:/Users/modin/Desktop/Ettore/UNIVERSITA/PISA_PROJECT/progetto-applied/data/pisa_data_final.csv",pisa_data)
write.csv(pisa_data,"C:/Users/modin/Desktop/Ettore/UNIVERSITA/PISA_PROJECT/progetto-applied/data/pisa_data_final.csv")
df=read.csv("../../data/pisa_data_final,csv")
source("../include/Utilities.R")
setwd("C:/Users/modin/Desktop/Ettore/UNIVERSITA/PISA_PROJECT/progetto-applied/src/data_prep/dimensionality-reduction")
source("../include/Utilities.R")
source("../../include/Utilities.R")
source("../../include/Utilities.R")
library(dplyr)
library(psych)
library(car)
library(MVN)
library(GGally)
library(ggplot2)
library(elasticnet)
library(magrittr)
library(vioplot)
df=read.csv("../../data/pisa_data_final,csv")
df=read.csv("../../data/pisa_data_final,csv")
df=read.csv("../../../data/pisa_data_final,csv")
df=read.csv("../../../../data/pisa_data_final,csv")
df=read.csv("../../../data/pisa_data_final,csv")
df=read.csv("../../data/pisa_data_final,csv")
df=read.csv("../data/pisa_data_final,csv")
df=read.csv("../data/pisa_data_final.csv")
df=read.csv("../../data/pisa_data_final.csv")
df=read.csv("../../../data/pisa_data_final.csv")
colnames(df)
head(df)
df=df[,-c(1)] #remove X (index) column
head(df)
# df <- df %>% select(-starts_with("PV")) #excluding target variables
df=df[,-c(1:20)] # same but surely works
colnames(df)
want_to_plot_all_couples=0
want_to_save_score_df=0
states = unique(df$CNT)
states
len = length(unique(df$CNT))
len
hcl.pals()
col.ramp = hcl.colors(len, palette = "viridis")
#loaded librarires
library(dplyr)
library(psych) #for KMO test and principal()
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check
library(GGally) #for ggcorr
library(ggplot2)
library(elasticnet) #trying out sparse principal component analysis [spca()]
library(tidyverse)
#DIRECTORIES
root_proj_dir = "../../../"
dataset_dir = paste(root_proj_dir,"/data/pisa_data_final.csv.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#IMPORTING THE DATASET
pisa_data <- read.csv(file=dataset_dir)
#DIRECTORIES
root_proj_dir = "../../../"
dataset_dir = paste(root_proj_dir,"/data/pisa_data_final.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#IMPORTING THE DATASET
pisa_data <- read.csv(file=dataset_dir)
head(pisa_data)
colnames(pisa_data)
#some adjustments on the data
pisa_data$X <- NULL
pisa_data$CNT <- as.factor(pisa_data$CNT)
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
head(pisa_data)
#paluesible values dataset
plausible_values <- pisa_data %>% select(starts_with("PV"))
#excluding PV frmo the dataset to compute the factor analysis
pisa_data <- pisa_data %>% select(-starts_with("PV")) #excluding target variables
pisa_data
#standardize the variables
transformed_data <- as.data.frame(scale(select_if(pisa_data,is.numeric)))
transformed_data$CNT <- pisa_data$CNT #adding CNT column
pisa_data <- transformed_data
rm(transformed_data)
boxplot(select_if(pisa_data,is.numeric),las=2)
grouped_variables <-list()
#list of grouped variables
##Technology
#c("ICTCLASS","ICTHOME","ICTOUTSIDE","ICTRES","AUTICT","COMPICT","INTICT","ENTUSE","HOMESCH","USESCH", "ICTSCH","RATCMP1")
grouped_variables[["ICT at home"]] <- c("ICTHOME","ICTRES","ENTUSE","HOMESCH")
grouped_variables[["Relationship with ICT"]] <- c("AUTICT","COMPICT","INTICT","ENTUSE", "HOMESCH", "USESCH")
grouped_variables[["ICT at school"]] <- c("ICTCLASS","ICTOUTSIDE","USESCH", "ICTSCH","RATCMP1")
##Psichology
grouped_variables[["Psychological Well-being"]] <- c("EUDMO","SWBP","GFOFAIL", "RESILIENCE", "COMPETE")
grouped_variables[["Social Well-Being"]] <- c("PERCOOP","PERCOMP","EMOSUPS","BELONG","BEINGBULLIED")
##Culture
grouped_variables[["Cultural possesion"]] <- c("CULTPOSS","HEDRES")
grouped_variables[["Attitude towards school"]] <- c("LMINS","MMINS","STUBEHA","ATTLNACT")
grouped_variables[["Reading"]] <- c("JOYREAD", "SCREADCOMP")
##Family
grouped_variables[["Family economic status"]] <- c("WEALTH","ESCS","HOMEPOS","BFMJ2","BMMJ1","HISCED","HISEI")
### consider only ESCS
grouped_variables[["Family economic status"]] <- "ESCS"
##Teaching
grouped_variables[["Teachers' degree"]] <- c("PROAT5AB","PROAT5AM","PROAT6")
grouped_variables[["Teacher support"]] <- c("TEACHINT","TEACHSUP","STIMREAD","TEACHBEHA")
##School
grouped_variables[["School size"]] <- c("STRATIO","SCHSIZE","CLSIZE")
grouped_variables[["Equipment of the school"]] <- c("EDUSHORT","STAFFSHORT")
#groups
group_list <- names(grouped_variables)
group_list
p_ <- GGally::print_if_interactive
#overall correlation overview
ggcorr(select_if(pisa_data, is.numeric),
label = TRUE,
label_size = 0.5)
for(group_name in group_list){
p_(ggcorr(pisa_data[,grouped_variables[[group_name]]],
label=TRUE,label_size = 2) +
ggtitle(group_name))
}
for(group in names(grouped_variables)){
cat("\nGroup: ", group,"\n\n")
print(KMO(pisa_data[,grouped_variables[[group]]]))
}
nfactors <- list()
for(group in group_list){
#scree plot
#scree(pisa_data[,grouped_variables[[group]]],
#      pc=TRUE,
#      main = paste("Scree plot:", group))
#parallel analysis
parallel.an <- fa.parallel(pisa_data[,grouped_variables[[group]]],
main = paste("Parallel Analysis Scree Plots:",group))
nfactors[[group]]$FA <- parallel.an$nfact
nfactors[[group]]$PC <- parallel.an$ncomp
#a method from psych package with many more criteria
#nfactors(cor(pisa_data[,grouped_variables[[group]]]),
#         title = paste("Number of factors", group),
#         plot=FALSE)
}
#TRIED methods:
# FA with principal factor method
fit_FA_MinRes <- list()
# rotated PCA
fit_PCA_rotated <- list()
#fitting the models
for(group in group_list){
#FA with MinRes
fit_FA_MinRes[[group]] <- fa(r = cor(pisa_data[,grouped_variables[[group]]]),
nfactors = nfactors[[group]]$FA,
rotate = "promax")
#advanced PCA
fit_PCA_rotated[[group]] <- principal(r = cor(pisa_data[,grouped_variables[[group]]]),
nfactors = nfactors[[group]]$PC,
rotate = "promax")
}
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
library(mvtnorm)
library(MVN)
library(rgl)
library(car)
library(dbscan)
library(cluster)
library(fields)
library(ggplot2)
library(GGally)
library(mvtnorm)
library(MVN)
library(rgl)
library(car)
library(dbscan)
library(cluster)
library(fields)
library(ggplot2)
library(GGally)
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_wPV_grouped_bysch_schtype.csv",sep=""))
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
#directories
dataset_dir = "../../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_wPV_grouped_bysch_schtype.csv",sep=""))
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
#directories
dataset_dir = "../../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
colnames(pisa_data)
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
pisa_data$X <- NULL
colnames(pisa_data)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
pisa_data$X <- NULL
colnames(pisa_data)
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
pisa_data$X <- NULL
colnames(pisa_data)
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
length(colnames(pisa_data))
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
pisa_data$X <- NULL
colnames(pisa_data)
length(colnames(pisa_data))
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
cat_var_names = c("tec","psi","clt","fam","tch","sch")
pisa_data
length(colnames(pisa_data))
pisa_data$X <- NULL
colnames(pisa_data)
length(colnames(pisa_data))
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
measures = pisa_data[,21:72]
rm( list = ls() )
list.files()
graphics.off() # chiude tutti i device grafici
cat("\014") #pulisci console
library(mvtnorm)
library(MVN)
library(rgl)
library(car)
library(dbscan)
library(cluster)
library(fields)
library(ggplot2)
library(GGally)
#directories
dataset_dir = "../../data/"
include_dir = "../include/Utilities.R"
#including utilities
source(include_dir)
#importing the dataset
pisa_data <- read.csv(file=paste(dataset_dir,"pisa_data_final.csv",sep=""))
pisa_data$X <- NULL
colnames(pisa_data)
length(colnames(pisa_data))
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)
measures = pisa_data[,21:72]
measures
measures = pisa_data[,21:71]
measures
colnames(pisa_data)
colnames(measures)
pisa_data
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 0.6
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = p+1
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 0.6
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = 15
dbs <- dbscan(measures, eps = eps_chosen, minPts = minpts)
dbs
plot(measures, col = dbs$cluster + 1L, pch=19)
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 0.6
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = 15
dbs <- dbscan(measures, eps = eps_chosen, minPts = minpts)
dbs
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 100
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = 15
dbs <- dbscan(measures, eps = eps_chosen, minPts = minpts)
dbs
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 80
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = 15
dbs <- dbscan(measures, eps = eps_chosen, minPts = minpts)
dbs
measures = pisa_data[,21:71]
colnames(measures)
# Rule of thumb, minPts = dimensionality + 1 = 3 here
# How to choose eps from minPts?
# Plot of the distances to the minPts nearest neighbor
k_chosen_2=2
kNNdistplot(measures, k = k_chosen_2)
eps_chosen = 60
abline(h = eps_chosen, col = "red", lty = 2)
# Run the dbscan
minpts = 15
dbs <- dbscan(measures, eps = eps_chosen, minPts = minpts)
dbs
# Let's compute the silhouette score on the clustering performed before
# WARNING (specific to DBSCAN): We need to remove the noise points as they do
# not belong to a cluster, before computing the silhouette score
clustered_index <- which(dbs$cluster != 0) # Index of non noise points
clustered_points <- measures[clustered_index,] # only clustered points
clustered_labels <- dbs$cluster[clustered_index] # corresponding labels
sil <- silhouette(clustered_labels, dist(clustered_points))
summary(sil)
sil_score <- function(labels, dist) {
# Compute the average of the silhouette widths
sil <- silhouette(labels, dist)
sil_widths <- sil[,"sil_width"]
mean(sil_widths)
}
sil_score(clustered_labels, dist(clustered_points))
# Grid Search
minPts_grid <- 1:20
eps_grid <- seq(from = 50, length.out=length(minPts_grid), by = 10)
max_share_noise <- 0.2
dbscan_perf <- function(minPts, eps) {
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(measures, eps, minPts) # Run dbscan
clustered_index <- which(dbs$cluster != 0) # Index of non noise points
clustered_points <- measures[clustered_index,] # only clustered points
clustered_labels <- dbs$cluster[clustered_index] # corresponding labels
nb_clusters <- length(unique(clustered_labels))
if ((nb_clusters > 1 & nb_clusters < n) & (length(which(dbs$cluster == 0))/n < max_share_noise)) {
# Silhouette score is defined only if 2 <= nb_clusters <= n-1
sil_score(clustered_labels, dist(clustered_points))
}
else {
# otherwise we return 0 which would be the approx. value of the silhouette
# score if the clusters were completely overlapping
0
}
}
# We compute the silhouette score for all combinations of minPts and eps
perf_grid <- outer(minPts_grid, eps_grid, FUN = Vectorize(dbscan_perf))
(nb_clusters > 1 & nb_clusters < n) & (length(which(dbs$cluster == 0))/n
n
n
n = dim(measures)[1]
n
n = dim(measures)[1]
# Grid Search
minPts_grid <- 1:20
eps_grid <- seq(from = 50, length.out=length(minPts_grid), by = 10)
max_share_noise <- 0.2
dbscan_perf <- function(minPts, eps) {
# Compute the silhouette score resulting from dbscan clustering
dbs <- dbscan(measures, eps, minPts) # Run dbscan
clustered_index <- which(dbs$cluster != 0) # Index of non noise points
clustered_points <- measures[clustered_index,] # only clustered points
clustered_labels <- dbs$cluster[clustered_index] # corresponding labels
nb_clusters <- length(unique(clustered_labels))
if ((nb_clusters > 1 & nb_clusters < n) & (length(which(dbs$cluster == 0))/n < max_share_noise)) {
# Silhouette score is defined only if 2 <= nb_clusters <= n-1
sil_score(clustered_labels, dist(clustered_points))
}
else {
# otherwise we return 0 which would be the approx. value of the silhouette
# score if the clusters were completely overlapping
0
}
}
# We compute the silhouette score for all combinations of minPts and eps
perf_grid <- outer(minPts_grid, eps_grid, FUN = Vectorize(dbscan_perf))
#loaded librarires
library(dplyr)
library(psych) #for KMO test and principal()
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check
library(GGally) #for ggcorr
library(ggplot2)
library(elasticnet) #trying out sparse principal component analysis [spca()]
library(tidyverse)
#loaded librarires
library(dplyr)
library(psych) #for KMO test and principal()
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check
library(GGally) #for ggcorr
library(ggplot2)
library(elasticnet) #trying out sparse principal component analysis [spca()]
library(tidyverse)
#DIRECTORIES
root_proj_dir = "."
dataset_dir = paste(root_proj_dir,"/data/pisa_data_final.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#DIRECTORIES
root_proj_dir = "/."
dataset_dir = paste(root_proj_dir,"/data/pisa_data_final.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#DIRECTORIES
root_proj_dir = ""
dataset_dir = paste(root_proj_dir,"/data/pisa_data_final.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
getwd()
