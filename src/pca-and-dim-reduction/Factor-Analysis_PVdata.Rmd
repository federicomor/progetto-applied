---
title: "Factor Analysis"
output: 
---

# NOTES AND REFERENCES

-   Exploratory Factor Analysis (EFA) tutorial: <https://rpubs.com/pjmurphy/758265>

-   notes from the textbook "Applied Multivariate Statistical Analysis" in the same directory of this folder

-   reference paper of past year project on Well-Being

-   source: <https://www.geo.fu-berlin.de/en/v/soga/Geodata-analysis/factor-analysis/A-simple-example-of-FA/index.htmlZ>

-   according to this article (<https://journals.sagepub.com/doi/full/10.1177/0095798418771807>) it is better to perform EFA only on variables we suspect to be generated by a latent factor. Thus, it is better to follow the same procedure we used for PCA

# PRELIMINARY STUFF

```{r}
#loaded librarires
library(dplyr)
library(psych) #for KMO test and principal()
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check
library(GGally) #for ggcorr
library(ggplot2)
library(elasticnet) #trying out sparse principal component analysis [spca()]
```

```{r, setup}
#DIRECTORIES
root_proj_dir = "../../"
dataset_dir = paste(root_proj_dir,"/data/pisa_wPV_grouped_bysch.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
#IMPORTING THE DATASET
pisa_data <- read.csv(file=dataset_dir)
```

```{r}
#some adjustments on the data
pisa_data$X <- NULL
pisa_data$schID <- NULL
pisa_data$CNT <- as.factor(pisa_data$CNT)
pisa_data$CNTSCHID <- as.factor(pisa_data$CNTSCHID)
pisa_data$CNTSTUID <- as.factor(pisa_data$CNTSTUID)
```

# PREPROCESSING OF DATA

Saving plausible values in a separate dataframe. Later we'll add them to the scores dataset

```{r}
#paluesible values dataset
plausible_values <- pisa_data %>% select(starts_with("PV"))
#excluding PV frmo the dataset to compute the factor analysis
pisa_data <- pisa_data %>% select(-starts_with("PV")) #excluding target variables
```

```{r}
#standardize the variables
transformed_data <- as.data.frame(scale(select_if(pisa_data,is.numeric)))
transformed_data$CNT <- pisa_data$CNT #adding CNT column

pisa_data <- transformed_data
rm(transformed_data)
```

Quick look at the data

```{r}
boxplot(select_if(pisa_data,is.numeric),las=2)
```

# GROUPING THE VARIABLES

Grouping variables suspected to be generated by a latent factor (The same variable may appear in more than one group, according to our choices):

```{r}
#variabili finite nel dataset
group_list <- c("tec","psi","clt","fam","tch","sch")
grouped_variables <-list()
#list of grouped variables
grouped_variables[["tec"]] <- c("ICTCLASS","ICTHOME","ICTOUTSIDE","ICTRES","AUTICT","COMPICT","INTICT","ENTUSE","HOMESCH","USESCH", "ICTSCH","RATCMP1")
grouped_variables[["psi"]] <- c("ATTLNACT","EMOSUPS","COMPETE","EUDMO","GFOFAIL","SWBP","RESILIENCE","BELONG","BEINGBULLIED","PERFEED")
grouped_variables[["clt"]] <- c("JOYREAD","CULTPOSS","HEDRES","SCREADCOMP","LMINS","MMINS","STUBEHA")
grouped_variables[["fam"]] <- c("WEALTH","ESCS","HOMEPOS","BFMJ2","BMMJ1","HISCED","HISEI","CULTPOSS","HEDRES","ICTHOME")
grouped_variables[["tch"]] <- c("TEACHINT","TEACHSUP","STIMREAD","PROAT5AB","PROAT5AM","PROAT6","TEACHBEHA")
grouped_variables[["sch"]] <- c("PERCOMP","PERCOOP","ICTSCH","RATCMP1","STRATIO","SCHSIZE","CLSIZE","CREACTIV","EDUSHORT","STAFFSHORT")
```

```{r}
#explainations
for(group in group_list){
  cat("Variables in group", group, "\n\n")
  for(var in grouped_variables[[group]]){
    cat(var, "\n")
    cat(spiega(var), "\n")
  }
  cat("\n")
}
```

Some graphs to validate the choice made while grouping the variables

```{r}
#OVERALL CORRELATION OVERVIEW
ggcorr(select_if(pisa_data,is.numeric),label=TRUE,label_size = 2)

#WITHIN GROUPS
#tec
ggcorr(select_if(pisa_data[,grouped_variables[["tec"]]],is.numeric),label=TRUE,label_size = 2)
#psi
ggcorr(select_if(pisa_data[,grouped_variables[["psi"]]],is.numeric),label=TRUE,label_size = 2)
#clt
ggcorr(select_if(pisa_data[,grouped_variables[["clt"]]],is.numeric),label=TRUE,label_size = 2)
#fam
ggcorr(select_if(pisa_data[,grouped_variables[["fam"]]],is.numeric),label=TRUE,label_size = 2)
#tch
ggcorr(select_if(pisa_data[,grouped_variables[["tch"]]],is.numeric),label=TRUE,label_size = 2)
#sch
ggcorr(select_if(pisa_data[,grouped_variables[["sch"]]],is.numeric),label=TRUE,label_size = 2)
```

# PERFORMING EFA

Preliminary tests:

-   cortest.bartlett(): test to see if the variables in the dataframe are uncorrellated. H0: correlation matrix sigma = Identity matrix (i.e. uncorrelated variables)

-   KMO: another check on uncorrelation

-   multivariate normality to perform factor analysis with the maximum likelihood estimation method

```{r}
checking_hp <- list()
for(group in group_list){
  #(1) CORRELATION
  #KMO(select_if(pisa_data[,included_variables[[group]]],is.numeric))
  checking_hp[[group]]$correlation <- cortest.bartlett(select_if(pisa_data[,grouped_variables[[group]]],is.numeric))
  #(2) MULTIVARIATE NORMALITY
  checking_hp[[group]]$normality <- mvn(data = select_if(pisa_data[,grouped_variables[[group]]],is.numeric), mvnTest = "hz",univariateTest = "SW")
}
```

Selecting the number of factor to select:

the following methods are useful to select the initial number of factors. The final choice should be made based on the portion of variance explained

```{r}
#eigenvalues method
for(group in group_list){
  #scree plot
  scree(select_if(pisa_data[,grouped_variables[[group]]],is.numeric), 
        pc=TRUE, 
        main = paste("Scree plot", group))
  #parallel analysis
  #fa.parallel(select_if(pisa_data[,grouped_variables[[group]]],is.numeric), 
  #            fa="fa", 
  #           main = paste("Parallel Analysis Scree Plots",group))
  #a method from psych package with many more criteria
  #nfactors(cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
  #         title = paste("Number of factors", group))
}
```

```{r}
#storing the number of factors (decision based on the previous plots)
nfactors <- list()
#tec
nfactors[["tec"]]$PC <- 6
nfactors[["tec"]]$FA <- 4
#psi
nfactors[["psi"]]$PC <- 5
nfactors[["psi"]]$FA <- 2
#clt
nfactors[["clt"]]$PC <- 4 
nfactors[["clt"]]$FA <- 3
#fam
nfactors[["fam"]]$PC <- 3 
nfactors[["fam"]]$FA <- 2 
#tch
nfactors[["tch"]]$PC <- 4 
nfactors[["tch"]]$FA <- 3
#sch
nfactors[["sch"]]$PC <- 6 
nfactors[["sch"]]$FA <- 3
```

Options:

-   factanal(): performs a EFA by maximum likelihood estimation [package stats]

-   princomp(): perform PCA in the stadard way, as seen in lecture [package stats]

-   fa(): performs various types of EFA, we can decided the most suited one [package psych]

-   principal(): performs PCA in a more sophisticated way, see the doxumentation in this folder [package psych]

```{r}
#TRIED methods:
# FA with ML
fit_FA_ML <- list() #factanal() 

# classical PCA 
fit_PCA_classic <- list() #princomp()

# FA with principal factor method
fit_FA_PF <- list() #fa() 

# advanced PCA
fit_PCA_advanced <- list()

#fitting the models
for(group in group_list){
  #FA with ML
  fit_FA_ML[[group]] <- fa(r = select_if(pisa_data[,grouped_variables[[group]]],is.numeric),
                            factors = nfactors[[group]]$FA, 
                            rotation = "promax", 
                            fm = "mle")
  #classic PCA
  fit_PCA_classic[[group]] <- princomp(select_if(pisa_data[,grouped_variables[[group]]],is.numeric))
  #FA with PF
  fit_FA_PF[[group]] <- fa(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
                            nfactors = nfactors[[group]]$FA,
                            rotate = "promax",
                            fm = "pa")
  #advanced PCA
  fit_PCA_advanced[[group]] <- principal(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
                               nfactors = nfactors[[group]]$PC, 
                               rotate = "promax", 
                               scores = TRUE)
  
}
```

**A note on rotation:** loading matrix (L) is unique up to rotation made through orthogonal matrices. Thus, we have can provide as an option to this functions a rotation method to ease the interpretability of the loadings. There a two kind of rotations:

-   orthogonal rotation methods: if we assume that the extracted factors are independent

    -   "varimax": optimized to reduce cross loadings and to minimize smaller loading values, making factor models clearer

    -   "quartimax": works to reduce the number of variables needed to explain a factor, making interpretation easier

    -   "equamax": compromise between varimax and quartimax

-   oblique rotation methods: if we assume that the extracted factors are not independent

    -   "promax": Promax rotation is popular for its ability to handle large datasets efficiently. The approach also tends to result in greater correlation values between factors.

    -   The direct "oblimin" rotation approach is somewhat less efficient with large datasets, but can produce a simpler factor structure.

[reference: <https://rpubs.com/pjmurphy/758265> for]

# LOADINGS AND GOF

## FA with Principal Factor solution method

Goodness of the model:

-   communalities: percentage of the variability of a single variable in the original dataframe explained by the common factors

-   factor.fit() compute the following quantity to asses the GOF of the model:

    -\> 1 - sum(residual_mat\*residual_mat')/sum(R\*R')

    where the sum is performed over each el. of the matrix

```{r}
for(group in group_list){
  cat("GROUP", group, "\n")
  #communalities
  cat("Communalities\n")
  print(fit_FA_PF[[group]]$communality)
  
  #fit of the model
  cat(group,"\n")
  print(factor.fit(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
             fit_FA_PF[[group]]))
}
```

Visualizing the loadings:

```{r}
#Factor Analysis with method "pa"
for(group in group_list){
  fa.diagram(fit_FA_PF[[group]])
  for(i in 1:dim(fit_FA_PF[[group]]$loadings)[2]){
    barplot(fit_FA_PF[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

## FA with ML method

Variance explained and GOF of the model (test to evaluate H0: sigma = LL' + phi)

```{r}
#variance explained
for(group in group_list){
  cat("GROUP", group, "\n\n")
  #communalities
  cat("-> Communalities\n")
  print(fit_FA_ML[[group]]$communality)
  
  #fit of the model
  cat("-> Fit coefficient:\n")
  print(factor.fit(r = cor(select_if(pisa_data[,grouped_variables[[group]]],is.numeric)),
             fit_FA_ML[[group]]))
  #GOF test
  cat("-> p-value for the GOF test\n")
  print(fit_FA_ML[[group]]$PVAL)
  
  cat("\n")
}
```

Visualize the loadings:

```{r}
#Factor Analysis with ML method 
for(group in group_list){
  fa.diagram(fit_FA_ML[[group]]$loadings)
  for(i in 1:dim(fit_FA_PF[[group]]$loadings)[2]){
    barplot(fit_FA_ML[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

## PCA

Evaluate the GOF of the model:

```{r}
for(group in group_list){
  cat("fit of the model for group", group, ":", fit_PCA_advanced[[group]]$fit,"\n")
  cat("fit of the model for group wrt off-diag elements for group ", group, ":", fit_PCA_advanced[[group]]$fit,"\n")
  
  summary(fit_PCA_advanced[[group]])
}

```

Visualize the loadings:

```{r}
#Principal Component method
for(group in group_list){
  for(i in 1:dim(fit_FA_PC[[group]]$loadings)[2]){
    barplot(fit_FA_OLS[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

## Classic PCA

```{r}
#BUG: I'M MISSING SOMETHING
for(group in group_list){
  print(summary(fit_classic_PC[[group]]))
}
```

```{r}
#Principal Component method
for(group in group_list){
  for(i in 1:dim(fit_classic_PC[[group]]$loadings)[2]){
    barplot(fit_classic_PC[[group]]$loadings[,i], main = paste("factor",group,i),las=2,cex.names=0.7)
  }
}
```

# COMPUTING THE SCORES

```{r}
#little utility to compute the scores from a fit of principal() and the dataframe on which the fit is computed
scores <- function(fit,data){
  return(as.data.frame(as.matrix(data)%*%fit$loadings))
}

#utiliy to name the dataframe
add_prefix <- function(prefix,x){
  return(paste(prefix,x,sep="_"))
}

FA_PC_scores <- data.frame(matrix(nrow = dim(pisa_data)[1], ncol = 0))
for(group in group_list){
  #score names
  PC_names <- as.character(1:nfactors[[group]])
  PC_names <- sapply(PC_names, add_prefix, prefix = group)
  PC_names <- sapply(PC_names, add_prefix, prefix = "PC")
  
  #computing the scores
  FA_PC_scores[,PC_names] <- scores(fit_FA_PC[[group]],select_if(pisa_data[,grouped_variables[[group]]],is.numeric))
}
```

Building and writing the score dataset:

```{r}
#add CNT column
FA_PC_scores$CNT <- pisa_data$CNT
#adding PVs
FA_PC_scores[,names(plausible_values)] <- plausible_values
```

```{r eval=FALSE, include=FALSE}
saving_dir <- "../../data"
write.csv(FA_PC_scores, file=paste(saving_dir,"pisa_wPV_PCscores.csv",sep="/"))
```
