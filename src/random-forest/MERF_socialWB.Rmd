# Mixed Effect Random Forest

## Settings

```{r}
#loaded librarires
library(dplyr)
library(car) #to apply transformations
library(MVN) #to perform multivariate gaussianity check

library(GGally) #for ggcorr
library(ggplot2)

library(randomForest) #bagging
library(gbm) #boosting

library(caret) #tuner for ML algorithms

library(glmnet)
library(lme4)
library(nlmeU) ## --> for the dataset
library(nlme)  ## --> for models implementation



library(corrplot)
library(lattice)
library(plot.matrix)

library(insight)
```

```{r}
set.seed(42)
#DIRECTORIES
root_proj_dir = "../../"
dataset_dir = paste(root_proj_dir,"/data/pisa_scores_final.csv",sep="")
include_dir = paste(root_proj_dir,"/src/include/Utilities.R",sep="")
#INCLUDING UTILITIES
source(include_dir)
source("funzione_LMERF.R")
#IMPORTING THE DATASET
pisa_data <- read.csv(file=dataset_dir)
```

```{r}
#some adjustments on the data
pisa_data$CNT <- as.factor(pisa_data$CNT)
pisa_data$SCHLTYPE <- as.factor(pisa_data$SCHLTYPE)

#standardizing
transformed_data <- as.data.frame(scale(select_if(pisa_data,is.numeric)))
transformed_data$CNT <- pisa_data$CNT #adding CNT column
transformed_data$SCHLTYPE <- pisa_data$SCHLTYPE #adding SCHLTYPE column

pisa_data <- transformed_data
rm(transformed_data)

pisa_data$X <- NULL
#check on data 
boxplot(select_if(pisa_data,is.numeric),las=2)


#shuffle data
shuffled_rows_index <- sample(1:nrow(pisa_data))
pisa_data <- pisa_data[shuffled_rows_index,]

#view the target
boxplot(pisa_data$Social.well.being, main = "Social.well.being")
```

# MERF: Naive try

## Fitting

### Fixed effects

Constructing the formula object

```{r}
#regressors
regressors <- names(pisa_data)
to_discard <- c("CNT", "Social.well.being", "Psychological.well.being", "SCHLTYPE")
regressors <- regressors[!regressors %in% to_discard]

#formula object
formula_str <- paste("Social.well.being", paste(regressors, collapse = "+"), sep ="~")
```

Tuning mtry

```{r}
# Create model with default paramters
control <- trainControl(method="oob", 
                        number=1, #number of folder in K-fold CV #number of repetitions
                        verboseIter = TRUE)

# grid
tunegrid <- expand.grid(.mtry = 5)

# training
rf_training <- train(as.formula(formula_str),
                     data = pisa_data, 
                     method = "rf", 
                     metric = "Rsquared", 
                     tuneGrid=tunegrid, 
                     trControl=control)

#printing the training results
print(rf_training)

#to see what's inside the method used to fit
getModelInfo(model = "rf", regex = FALSE)

final_rf <- rf_training$finalModel
```

```{r}
#contribution of the regressors
randomForest::importance(final_rf)
varImpPlot(final_rf)
```

### Random effects

```{r}
fix_effect.pred <- final_rf$predicted

#including random effects in the formula
random_intercepts <- c("(1|CNT)")

ME_formula_str <- paste("Social.well.being", paste(random_intercepts,collapse="+"), sep="~")
```

```{r}
lme_fit <- lmer(ME_formula_str, 
                data=pisa_data,
                offset = fix_effect.pred)

lme_fit
```

## Evaluation

### Fixed effects

```{r}
R2 <- 1 - var(final_rf$y - final_rf$predicted) / var(final_rf$y) 
R2
```

### Mixed effects

PVRE

```{r}
sigma2_eps <- as.numeric(get_variance_residual(lme_fit))
sigma2_b <- as.numeric(get_variance_random(lme_fit))

PVRE <- sigma2_b/(sigma2_b+sigma2_eps)
PVRE
```

Trying pseudo R\^2

```{r}
# library(MuMIn)

# r.squaredGLMM(lme_fit)

#to compute the variance of the fixed effect variance on the variance
sigma2_f <- as.numeric(get_variance_fixed(lme_fit)) #0.91791^2*var(final_rf$predicted)

(sigma2_f+sigma2_b)/(sigma2_b+sigma2_f+sigma2_eps)
```

MSE

```{r}
#mean squared error of the fixed effect
mean((pisa_data$Social.well.being-final_rf$predicted)^2)

#mean squared error of the mixed model
mean((pisa_data$Social.well.being-fitted(lme_fit))^2)
```

## Interpretations

### Fixed effects

Importance

```{r}
varImpPlot(final_rf)
```

Partial plots

```{r}
threshold_imp <- 200

for(reg in regressors[randomForest::importance(final_rf) > threshold_imp]){
  partialPlot(final_rf,
              pred.data = pisa_data,
              x.var = as.character(reg),
              main = paste("Dependence on",reg)
              )
}
```

### Mixed effects

Dotplot

```{r}
dotplot(ranef(lme_fit, condVar=T))
```

# MERF: rigorous implementation

Implementation following the procedure of Masci's paper. You can find it in the docs in the folder random-forest

## Fitting

```{r}
#function lmerf fit a MERF following an iterative procedure, which alternates the fitting of a random forest with the fitting of mixed effect model, incorporating the two
fit_lmerf <- lmerf(y = pisa_data$Social.well.being,
                   cov = pisa_data[,regressors],
                   group = pisa_data$CNT,
                   xnam = regressors,
                   mtry = 5,
                   ntrees = 500,
                   toll = 0.03)

summary.lmerf(fit_lmerf)
```

## Evaluation

### Fixed effects

```{r}
forest.model <- fit_lmerf$forest.model

#inspecting fixed effect
y_hat_forest <- forest.model$predicted
target_forest <- forest.model$y

MSE_forest <- mean((target_forest-y_hat_forest)^2)
MSE_forest #MSE represents the unexplained variance

Rsq <- 1 - MSE_forest/var(target_forest)
Rsq

#what's target_forest?

# *** by lmerf function ***
# target=rep(0,N) #target=y-Z%*%b
# for (i in 1:N) {
# 	b.temp=as.matrix(bi[group[i]], nrow=q, ncol=1)
# 	z.temp=as.matrix(Zi.int[i,], nrow=1, ncol=q)
# 	target[i]= y[i] - z.temp%*%b.temp
# }
```

### Mixed effects

Comparing the MSE with the one from the Naive implementation we see that we're increasing the performance

```{r}
y_hat <- fitted.lmerf(fit_lmerf)
y <- pisa_data$Social.well.being

#mean squared error of the MERF
mean((y-y_hat)^2)
```

PVRE

```{r}
sigma2_eps <- as.numeric(get_variance_residual(fit_lmerf$lmer.model))
sigma2_b <- as.numeric(get_variance_random(fit_lmerf$lmer.model))

PVRE <- sigma2_b/(sigma2_b+sigma2_eps)
PVRE
```

## Interpretations

### Fixed effect

Importance

```{r}
varImpPlot(fit_lmerf$forest.model)
```

Partial plots

```{r}
threshold_imp <- 150

for(reg in regressors[randomForest::importance(fit_lmerf$forest.model) > threshold_imp]){
  partialPlot(fit_lmerf$forest.model,
              pred.data = pisa_data,
              x.var = as.character(reg),
              main = paste("Dependence on",reg)
              )
}
```

### Mixed effect

```{r}
dotplot(ranef(fit_lmerf$lmer.model))
```
